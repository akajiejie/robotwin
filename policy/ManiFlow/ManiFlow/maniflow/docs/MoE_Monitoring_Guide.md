# MoE å’Œ Gate-Attention ç›‘æ§æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜äº†é’ˆå¯¹ Tokençº§MoE å’Œ Gate-Attention æœºåˆ¶çš„å››ä¸ªæ ¸å¿ƒç›‘æ§ç»´åº¦ã€‚

## ğŸ“Š å››ä¸ªæ ¸å¿ƒç›‘æ§ç»´åº¦

### 1. MoE ä¸“å®¶è´Ÿè½½ï¼ˆExpert Loadï¼‰

**ç›‘æ§æŒ‡æ ‡ï¼ˆå…¨å±€ï¼‰ï¼š**
- `moe/expert_entropy_normalized`: å½’ä¸€åŒ–ç†µå€¼ï¼ˆ0-1ä¹‹é—´ï¼Œæ‰€æœ‰blockå¹³å‡ï¼‰
- `moe/expert_collapse_warning`: ä¸“å®¶åç¼©è­¦å‘Šï¼ˆ1.0è¡¨ç¤ºè­¦å‘Šï¼‰
- `moe/avg_aux_loss`: MoEè¾…åŠ©æŸå¤±ï¼ˆè´Ÿè½½å‡è¡¡æŸå¤±ï¼‰
- `moe/expert_usage_std`: ä¸“å®¶ä½¿ç”¨ç‡çš„æ ‡å‡†å·®ï¼ˆè¶Šå°è¶Šå‡è¡¡ï¼‰

**å­¦æœ¯æ´å¯Ÿï¼š**
- **ç†µå€¼ï¼ˆEntropyï¼‰**è¡¡é‡ä¸“å®¶ä½¿ç”¨çš„å‡åŒ€ç¨‹åº¦
- **é«˜ç†µå€¼**ï¼ˆæ¥è¿‘æœ€å¤§ç†µï¼‰ï¼šä¸“å®¶ä½¿ç”¨å‡åŒ€ï¼Œè´Ÿè½½å‡è¡¡è‰¯å¥½
- **ä½ç†µå€¼**ï¼ˆ< 0.5 å½’ä¸€åŒ–ç†µï¼‰ï¼šå‡ºç°"ä¸“å®¶åç¼©"ï¼ˆExpert Collapseï¼‰ï¼Œåªæœ‰æå°‘æ•°ä¸“å®¶å·¥ä½œ
- **è§£å†³æ–¹æ¡ˆ**ï¼šå¦‚æœç†µå€¼è¿‡ä½ï¼Œéœ€è¦è°ƒå¤§ `aux_loss_alpha`ï¼ˆè¾…åŠ©æŸå¤±æƒé‡ï¼‰

**WandB ç›‘æ§ç¤ºä¾‹ï¼š**
```python
# åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§ï¼ˆåªæœ‰å…¨å±€æŒ‡æ ‡ï¼‰
moe/expert_entropy_normalized  # ä¸»è¦å…³æ³¨è¿™ä¸ªæŒ‡æ ‡ï¼Œåº”è¯¥ > 0.7
moe/expert_collapse_warning    # å¦‚æœä¸º1.0ï¼Œéœ€è¦è°ƒæ•´è¶…å‚æ•°
moe/avg_aux_loss              # è¾…åŠ©æŸå¤±ï¼Œè§‚å¯Ÿæ˜¯å¦æ”¶æ•›
moe/expert_usage_std          # ä¸“å®¶ä½¿ç”¨å‡è¡¡åº¦ï¼Œåº”è¯¥è¾ƒå°
```

---

### 2. Gate-Attention æ¿€æ´»åˆ†å¸ƒ

**ç›‘æ§æŒ‡æ ‡ï¼ˆå…¨å±€ï¼‰ï¼š**
- `gate/activation_mean`: Gateæ¿€æ´»å€¼çš„å‡å€¼ï¼ˆæ‰€æœ‰blockå¹³å‡ï¼‰
- `gate/activation_std`: Gateæ¿€æ´»å€¼çš„æ ‡å‡†å·®ï¼ˆæ‰€æœ‰blockå¹³å‡ï¼‰
- `gate/no_filtering_warning`: é—¨æ§å¤±æ•ˆè­¦å‘Šï¼ˆ1.0è¡¨ç¤ºè­¦å‘Šï¼‰

**å­¦æœ¯æ´å¯Ÿï¼š**
- Gate-Attention é€šè¿‡ `sigmoid(gate_score)` è°ƒåˆ¶ cross-attention è¾“å‡º
- **æ¿€æ´»å€¼æ¥è¿‘1**ï¼ˆ> 0.95ï¼‰ï¼šè¯´æ˜é—¨æ§æ²¡æœ‰èµ·åˆ°è¿‡æ»¤ä½œç”¨ï¼Œæ‰€æœ‰æ¨¡æ€éƒ½è¢«å®Œå…¨ä¿ç•™
- **æ¿€æ´»å€¼åˆ†å¸ƒä¸å‡**ï¼šæŸäº›æ¨¡æ€ï¼ˆå¦‚tactileï¼‰åœ¨ç‰¹å®šä»»åŠ¡é˜¶æ®µæ¿€æ´»å€¼æ˜¾è‘—å‡é«˜ï¼Œè¯´æ˜æ¨¡å‹å­¦ä¼šäº†æ¨¡æ€é‡è¦æ€§åˆ†é…
- **ç†æƒ³çŠ¶æ€**ï¼šæ¿€æ´»å€¼åœ¨ 0.3-0.9 ä¹‹é—´åŠ¨æ€å˜åŒ–ï¼Œæ ‡å‡†å·®è¾ƒå¤§

**WandB ç›‘æ§ç¤ºä¾‹ï¼š**
```python
# ä¸»è¦ç›‘æ§æŒ‡æ ‡ï¼ˆåªæœ‰å…¨å±€ï¼‰
gate/activation_mean           # åº”è¯¥åœ¨ 0.5-0.8 ä¹‹é—´
gate/activation_std            # åº”è¯¥ > 0.1ï¼Œè¯´æ˜æœ‰é€‰æ‹©æ€§
gate/no_filtering_warning      # å¦‚æœä¸º1.0ï¼Œè¯´æ˜é—¨æ§å¤±æ•ˆ
```

**å®éªŒå»ºè®®ï¼š**
- å¯ä»¥æŒ‰æ¨¡æ€åˆ†åˆ«è®°å½•gateæ¿€æ´»å€¼ï¼ˆéœ€è¦é¢å¤–ä¿®æ”¹ä»£ç ï¼‰
- è§‚å¯Ÿåœ¨ä¸åŒä»»åŠ¡é˜¶æ®µï¼ˆå¦‚æŠ“å–ã€æ”¾ç½®ï¼‰gateæ¿€æ´»å€¼çš„å˜åŒ–

---

### 3. æ¢¯åº¦èŒƒæ•°ï¼ˆGradient Normsï¼‰

**ç›‘æ§æŒ‡æ ‡ï¼ˆå…¨å±€ï¼‰ï¼š**
- `grad/moe_gate_grad_norm`: MoEè·¯ç”±æƒé‡çš„æ¢¯åº¦èŒƒæ•°ï¼ˆæ‰€æœ‰blockå¹³å‡ï¼‰
- `grad/moe_gate_grad_overflow`: æ¢¯åº¦æº¢å‡ºè­¦å‘Šï¼ˆ1.0è¡¨ç¤ºè­¦å‘Šï¼‰
- `grad/time_modulation_grad_norm`: æ—¶é—´æ¡ä»¶è°ƒåˆ¶çš„æ¢¯åº¦èŒƒæ•°ï¼ˆæ‰€æœ‰blockå¹³å‡ï¼‰

**å­¦æœ¯æ´å¯Ÿï¼š**
- **è·¯ç”±å±‚è®­ç»ƒæå…¶ä¸ç¨³å®š**ï¼šMoEçš„gateç½‘ç»œå®¹æ˜“å‡ºç°æ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±
- **æ¢¯åº¦èŒƒæ•° > 10.0**ï¼šéœ€è¦å¼•å…¥ Gradient Clipping
- **æ¢¯åº¦èŒƒæ•° < 0.01**ï¼šå¯èƒ½å‡ºç°æ¢¯åº¦æ¶ˆå¤±ï¼Œå­¦ä¹ åœæ»

**WandB ç›‘æ§ç¤ºä¾‹ï¼š**
```python
# ä¸»è¦ç›‘æ§æŒ‡æ ‡ï¼ˆæ¯100æ­¥è®°å½•ä¸€æ¬¡ï¼Œå…¨å±€å¹³å‡ï¼‰
grad/moe_gate_grad_norm           # åº”è¯¥åœ¨ 0.1-5.0 ä¹‹é—´
grad/time_modulation_grad_norm    # åº”è¯¥åœ¨ 0.1-5.0 ä¹‹é—´
grad/moe_gate_grad_overflow       # å¦‚æœä¸º1.0ï¼Œéœ€è¦Grad Clipping
```

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# å¦‚æœæ¢¯åº¦æº¢å‡ºï¼Œåœ¨optimizeré…ç½®ä¸­æ·»åŠ ï¼š
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

---

### 4. æ—¶é—´æ¡ä»¶å…³è”åº¦ï¼ˆTime Conditioning Correlationï¼‰

**ç›‘æ§æŒ‡æ ‡ï¼ˆå…¨å±€ï¼‰ï¼š**
- `time_cond/modulation_l2_norm`: æ—¶é—´è°ƒåˆ¶æƒé‡çš„L2èŒƒæ•°ï¼ˆæ‰€æœ‰blockå¹³å‡ï¼Œæ¯100æ­¥è®°å½•ï¼‰
- `time_cond_epoch/modulation_l2_norm`: æ—¶é—´è°ƒåˆ¶æƒé‡çš„L2èŒƒæ•°ï¼ˆæ‰€æœ‰blockå¹³å‡ï¼Œæ¯ä¸ªepochè®°å½•ï¼‰

**å­¦æœ¯æ´å¯Ÿï¼š**
- æ—¶é—´æ¡ä»¶é€šè¿‡ `time_gate_modulation` è°ƒåˆ¶MoEçš„gate logits
- **æƒé‡èŒƒæ•°å¢å¤§**ï¼šè¯´æ˜æ—¶é—´æ¡ä»¶å¯¹ä¸“å®¶é€‰æ‹©çš„å½±å“å¢å¼º
- **ä¸åŒæ‰©æ•£æ—¶é—´æ­¥çš„ä¸“å®¶é€‰æ‹©å·®å¼‚**ï¼š
  - **æ—©æœŸæ—¶é—´æ­¥ï¼ˆtæ¥è¿‘0ï¼‰**ï¼šå™ªå£°è¾ƒå¤šï¼Œå¯èƒ½æ›´ä¾èµ–è§†è§‰ä¸“å®¶
  - **åæœŸæ—¶é—´æ­¥ï¼ˆtæ¥è¿‘1ï¼‰**ï¼šæ¥è¿‘ç›®æ ‡ï¼Œå¯èƒ½æ›´ä¾èµ–è§¦è§‰ä¸“å®¶
- **ç†æƒ³çŠ¶æ€**ï¼šæƒé‡L2èŒƒæ•°éšè®­ç»ƒé€æ¸å¢å¤§ï¼Œè¯´æ˜æ¨¡å‹å­¦ä¼šäº†æ—¶é—´æ„ŸçŸ¥

**WandB ç›‘æ§ç¤ºä¾‹ï¼š**
```python
# ä¸»è¦ç›‘æ§æŒ‡æ ‡ï¼ˆå…¨å±€å¹³å‡ï¼‰
time_cond/modulation_l2_norm        # æ¯100æ­¥è®°å½•ï¼Œè§‚å¯Ÿå˜åŒ–è¶‹åŠ¿
time_cond_epoch/modulation_l2_norm  # æ¯ä¸ªepochè®°å½•ï¼Œåº”è¯¥éšè®­ç»ƒå¢å¤§
```

**å®éªŒå»ºè®®ï¼š**
- å¯ä»¥åœ¨ä¸åŒçš„æ‰©æ•£æ—¶é—´æ­¥ï¼ˆt=0.1, 0.5, 0.9ï¼‰åˆ†åˆ«è®°å½•ä¸“å®¶é€‰æ‹©åˆ†å¸ƒ
- è§‚å¯Ÿæ—¶é—´æ¡ä»¶å¯¹ä¸“å®¶é€‰æ‹©çš„å½±å“æ˜¯å¦æ˜¾è‘—

---

## ğŸ¯ ç›‘æ§æ€»ç»“

### å…³é”®æŒ‡æ ‡ä¸€è§ˆè¡¨

| ç»´åº¦ | æ ¸å¿ƒæŒ‡æ ‡ | å¥åº·èŒƒå›´ | è­¦å‘Šé˜ˆå€¼ | è§£å†³æ–¹æ¡ˆ |
|------|---------|---------|---------|---------|
| **ä¸“å®¶è´Ÿè½½** | `moe/expert_entropy_normalized` | > 0.7 | < 0.5 | è°ƒå¤§ `aux_loss_alpha` |
| **Gateæ¿€æ´»** | `gate/activation_mean` | 0.5-0.8 | > 0.95 | æ£€æŸ¥gateåˆå§‹åŒ– |
| **æ¢¯åº¦èŒƒæ•°** | `grad/moe_gate_grad_norm` | 0.1-5.0 | > 10.0 | æ·»åŠ  Grad Clipping |
| **æ—¶é—´æ¡ä»¶** | `time_cond_epoch/modulation_l2_norm` | é€æ¸å¢å¤§ | é•¿æœŸä¸å˜ | æ£€æŸ¥æ—¶é—´åµŒå…¥ |

### WandB Dashboard æ¨èå¸ƒå±€ï¼ˆç®€åŒ–ç‰ˆï¼‰

**Panel 1: MoE ä¸“å®¶è´Ÿè½½**
- `moe/expert_entropy_normalized` (æŠ˜çº¿å›¾) - ä¸»è¦æŒ‡æ ‡
- `moe/expert_collapse_warning` (æ ‡è®°)
- `moe/avg_aux_loss` (æŠ˜çº¿å›¾)
- `moe/expert_usage_std` (æŠ˜çº¿å›¾)

**Panel 2: Gate-Attention æ¿€æ´»**
- `gate/activation_mean` (æŠ˜çº¿å›¾) - ä¸»è¦æŒ‡æ ‡
- `gate/activation_std` (æŠ˜çº¿å›¾)
- `gate/no_filtering_warning` (æ ‡è®°)

**Panel 3: æ¢¯åº¦ç›‘æ§**
- `grad/moe_gate_grad_norm` (æŠ˜çº¿å›¾) - ä¸»è¦æŒ‡æ ‡
- `grad/time_modulation_grad_norm` (æŠ˜çº¿å›¾)
- `grad/moe_gate_grad_overflow` (æ ‡è®°)

**Panel 4: æ—¶é—´æ¡ä»¶å…³è”**
- `time_cond_epoch/modulation_l2_norm` (æŠ˜çº¿å›¾) - ä¸»è¦æŒ‡æ ‡
- `time_cond/modulation_l2_norm` (æŠ˜çº¿å›¾ï¼Œæ›´é«˜é¢‘ç‡ï¼‰

---

## ğŸ”¬ å®éªŒå»ºè®®

### 1. ä¸“å®¶åç¼©è¯Šæ–­
```python
# å¦‚æœ moe/avg_expert_entropy_normalized < 0.5
# å°è¯•ä»¥ä¸‹è°ƒæ•´ï¼š
moe_aux_loss_alpha: 0.01 -> 0.05  # å¢å¤§è´Ÿè½½å‡è¡¡æŸå¤±
num_experts: 4 -> 8                # å¢åŠ ä¸“å®¶æ•°é‡
```

### 2. Gateå¤±æ•ˆè¯Šæ–­
```python
# å¦‚æœ gate/avg_activation_mean > 0.95
# æ£€æŸ¥gateåˆå§‹åŒ–ï¼š
# åœ¨ CrossAttention.__init__ ä¸­ç¡®ä¿ï¼š
nn.init.zeros_(self.q.weight)  # gateéƒ¨åˆ†åˆå§‹åŒ–ä¸º0
```

### 3. æ¢¯åº¦çˆ†ç‚¸å¤„ç†
```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ ï¼š
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

### 4. æ—¶é—´æ¡ä»¶åˆ†æ
```python
# åœ¨ä¸åŒæ—¶é—´æ­¥è®°å½•ä¸“å®¶é€‰æ‹©
# ä¿®æ”¹ forward å‡½æ•°ï¼Œè®°å½• t å’Œ topk_idx çš„å…³ç³»
```

---

## ğŸ“ ä»£ç ä¿®æ”¹ä½ç½®

1. **ditx_moe_block.py**
   - `DiTXMoEBlock.get_moe_stats()`: æ·»åŠ ç†µå€¼è®¡ç®—
   - `CrossAttention.forward()`: æ”¶é›†gateæ¿€æ´»ç»Ÿè®¡

2. **maniflow_image_policy.py**
   - `compute_loss()`: æ”¶é›†MoEå’ŒGateç»Ÿè®¡ï¼Œæ·»åŠ è­¦å‘Šæ ‡å¿—

3. **train_maniflow_robotwin2_workspace.py**
   - è®­ç»ƒå¾ªç¯: æ·»åŠ æ¢¯åº¦èŒƒæ•°ç›‘æ§
   - æ¯100æ­¥: è®°å½•æ—¶é—´æ¡ä»¶æƒé‡
   - æ¯ä¸ªepoch: è®°å½•è¯¦ç»†ç»Ÿè®¡

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

1. ç¡®ä¿é…ç½®æ–‡ä»¶ä¸­å¯ç”¨äº†MoEå’ŒGate-Attentionï¼š
```yaml
policy:
  use_token_moe: true
  num_experts: 4
  gate_type: 'headwise'  # or 'elementwise'
```

2. å¯åŠ¨è®­ç»ƒï¼Œåœ¨WandBä¸­æŸ¥çœ‹ä»¥ä¸‹**4ä¸ªæ ¸å¿ƒå…¨å±€æŒ‡æ ‡**ï¼š
   - `moe/expert_entropy_normalized` - ä¸“å®¶è´Ÿè½½å‡è¡¡åº¦
   - `gate/activation_mean` - Gateæ¿€æ´»æ°´å¹³
   - `grad/moe_gate_grad_norm` - æ¢¯åº¦ç¨³å®šæ€§
   - `time_cond_epoch/modulation_l2_norm` - æ—¶é—´æ¡ä»¶å­¦ä¹ ç¨‹åº¦

3. æ ¹æ®ç›‘æ§ç»“æœè°ƒæ•´è¶…å‚æ•°

**æ³¨æ„ï¼š** æ‰€æœ‰æŒ‡æ ‡éƒ½æ˜¯å…¨å±€å¹³å‡å€¼ï¼ˆè·¨æ‰€æœ‰blockï¼‰ï¼Œç®€åŒ–ç›‘æ§ï¼Œä¾¿äºè§‚å¯Ÿæ”¶æ•›è¶‹åŠ¿ã€‚

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

- **MoEè´Ÿè½½å‡è¡¡**: Switch Transformers (Google, 2021)
- **Gate-Attention**: Qwen3 Technical Report (Alibaba, 2024)
- **æ—¶é—´æ¡ä»¶MoE**: æœ¬é¡¹ç›®åˆ›æ–°ç‚¹
- **æ¢¯åº¦ç¨³å®šæ€§**: On the Difficulty of Training Recurrent Neural Networks (2013)

