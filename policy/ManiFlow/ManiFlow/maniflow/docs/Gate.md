# GateæŠ‘åˆ¶é—®é¢˜è¯Šæ–­ä¸è§£å†³æ–¹æ¡ˆ

## ğŸš¨ é—®é¢˜æè¿°

### å½“å‰ç—‡çŠ¶
```
âœ— mean_activation < 0.1        â†’ Gateå‡ ä¹å®Œå…¨å…³é—­ï¼ˆæ­£å¸¸åº”ä¸º0.3-0.7ï¼‰
âœ— saturation_low_ratio > 0.8   â†’ 80%çš„gateå€¼<0.1ï¼Œæ¨¡æ€è¢«å¤§é‡å¿½ç•¥
âœ— saturation_high_ratio = 0.02 â†’ å‡ ä¹æ²¡æœ‰gateè¢«å……åˆ†æ¿€æ´»
âœ— train_loss ä¸‹é™              â†’ æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šå­¦ä¹ 
âœ— val_loss ä¸Šå‡                â†’ ä¸¥é‡è¿‡æ‹Ÿåˆ
âœ— train_action_mse_error å…ˆé™åå‡ â†’ æ¨¡å‹å¼€å§‹è®°å¿†è€Œéæ³›åŒ–
```

### é—®é¢˜æœ¬è´¨

è¿™æ˜¯ä¸€ä¸ª**Gateåˆå§‹åŒ–ä¸å½“ + è¿‡æ‹Ÿåˆ**çš„å¤åˆé—®é¢˜ï¼š

1. **Gateè¿‡åº¦æŠ‘åˆ¶**: æ¨¡å‹å­¦ä¼šäº†"å…³é—­"å¤§éƒ¨åˆ†ä¿¡æ¯æµï¼Œåªä½¿ç”¨æå°‘é‡ç‰¹å¾
2. **è¿‡æ‹Ÿåˆ**: æ¨¡å‹åœ¨æœ‰é™çš„ä¿¡æ¯ä¸Šè®°å¿†è®­ç»ƒé›†ï¼Œæ— æ³•æ³›åŒ–åˆ°éªŒè¯é›†
3. **ä¿¡æ¯ç“¶é¢ˆ**: Gateå…³é—­å¯¼è‡´æ¢¯åº¦æµå—é˜»ï¼Œæ¨¡å‹éš¾ä»¥å­¦ä¹ æœ‰æ•ˆç‰¹å¾

---

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šä¿®æ”¹Gateåˆå§‹åŒ–ï¼ˆæ¨èï¼Œéœ€é‡å¯è®­ç»ƒï¼‰

#### 1. ä¿®æ”¹ `ditx_gateattn_block.py`

æ‰¾åˆ° `DiTXGateAttnBlock` çš„åˆå§‹åŒ–éƒ¨åˆ†ï¼Œä¿®æ”¹gate biasåˆå§‹åŒ–ï¼š

```python
# åœ¨ ditx_gateattn_block.py ä¸­æ‰¾åˆ° set_modality_ranges æ–¹æ³•
def set_modality_ranges(self, modality_info: dict):
    """
    ä¸ºä¸åŒæ¨¡æ€è®¾ç½®gate biasåˆå§‹å€¼
    
    ä¿®æ”¹ç­–ç•¥ï¼š
    - åŸå§‹: biasåˆå§‹åŒ–ä¸º0 â†’ sigmoid(0) = 0.5
    - é—®é¢˜: è®­ç»ƒè¿‡ç¨‹ä¸­å®¹æ˜“é™åˆ°0.1ä»¥ä¸‹
    - æ–°ç­–ç•¥: biasåˆå§‹åŒ–ä¸ºæ­£å€¼ â†’ sigmoid(1.0) = 0.73
    """
    if self.gate_type == 'none':
        return
    
    device = self.cross_attn.gate_proj.weight.device
    L_context = self.cross_attn.gate_proj.weight.shape[0]
    
    # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæé«˜åˆå§‹biaså€¼
    # åŸå§‹: bias = 0.0 â†’ gate â‰ˆ 0.5
    # æ–°å€¼: bias = 1.0 â†’ gate â‰ˆ 0.73 (æ›´å¼€æ”¾)
    INIT_BIAS = 1.0  # å¯è°ƒæ•´èŒƒå›´: 0.5-2.0
    
    with torch.no_grad():
        if self.gate_type == 'elementwise':
            # Elementwise gate: æ¯ä¸ªtokenä½ç½®ä¸€ä¸ªbias
            new_bias = torch.full((L_context,), INIT_BIAS, device=device)
            
            # å¯é€‰ï¼šä¸ºä¸åŒæ¨¡æ€è®¾ç½®ä¸åŒçš„åˆå§‹bias
            start_idx = 0
            for modality, n_tokens in modality_info.items():
                if modality in ['head', 'rgb_wrist']:
                    # RGBç›¸æœºï¼šç¨é«˜çš„åˆå§‹å€¼ï¼ˆè§†è§‰é€šå¸¸é‡è¦ï¼‰
                    new_bias[start_idx:start_idx + n_tokens] = 1.2
                elif modality == 'tactile':
                    # è§¦è§‰ï¼šä¸­ç­‰åˆå§‹å€¼
                    new_bias[start_idx:start_idx + n_tokens] = 1.0
                elif modality == 'proprio':
                    # æœ¬ä½“æ„ŸçŸ¥ï¼šä¸­ç­‰åˆå§‹å€¼
                    new_bias[start_idx:start_idx + n_tokens] = 1.0
                start_idx += n_tokens
            
            self.cross_attn.gate_proj.bias.copy_(new_bias)
            
        elif self.gate_type == 'headwise':
            # Headwise gate: æ‰€æœ‰headå…±äº«ä¸€ä¸ªbias
            new_bias = torch.full((self.num_heads,), INIT_BIAS, device=device)
            self.cross_attn.gate_proj.bias.copy_(new_bias)
```

#### 2. æ·»åŠ Gateæ­£åˆ™åŒ–ï¼ˆé˜²æ­¢è¿‡åº¦æŠ‘åˆ¶ï¼‰

åœ¨ `ditx_gateattn_block.py` çš„ `CrossAttentionGate` ç±»ä¸­æ·»åŠ ï¼š

```python
def forward(self, q, kv, **kwargs):
    """
    å‰å‘ä¼ æ’­ï¼Œæ·»åŠ gateæ­£åˆ™åŒ–
    """
    # ... åŸæœ‰ä»£ç  ...
    
    # è®¡ç®—gateå€¼
    if self.gate_type == 'elementwise':
        gate = torch.sigmoid(self.gate_proj(kv.mean(dim=1)))  # (B, L_context)
        gate = gate.unsqueeze(1).unsqueeze(1)  # (B, 1, 1, L_context)
    elif self.gate_type == 'headwise':
        gate = torch.sigmoid(self.gate_proj.weight)  # (num_heads,)
        gate = gate.view(1, -1, 1, 1)  # (1, num_heads, 1, 1)
    
    # ğŸ”¥ æ–°å¢ï¼šGateæ­£åˆ™åŒ–ï¼ˆè®­ç»ƒæ—¶ï¼‰
    if self.training:
        # é˜²æ­¢gateè¿‡åº¦é¥±å’Œï¼ˆè¿‡é«˜æˆ–è¿‡ä½ï¼‰
        # é¼“åŠ±gateå€¼ä¿æŒåœ¨0.2-0.8ä¹‹é—´
        gate_penalty = torch.mean(
            torch.relu(0.2 - gate) +  # æƒ©ç½š<0.2çš„gate
            torch.relu(gate - 0.8)     # æƒ©ç½š>0.8çš„gate
        )
        # è¿™ä¸ªpenaltyéœ€è¦åœ¨lossä¸­æ·»åŠ ï¼ˆè§ä¸‹æ–‡ï¼‰
        self._gate_penalty = gate_penalty
    
    # åº”ç”¨gate
    attn_output = attn_output * gate
    
    return attn_output
```

#### 3. ä¿®æ”¹è®­ç»ƒlossï¼ˆæ·»åŠ gateæ­£åˆ™åŒ–é¡¹ï¼‰

åœ¨ `maniflow_image_policy.py` çš„ `compute_loss` æ–¹æ³•ä¸­ï¼š

```python
def compute_loss(self, batch, ema_model=None, **kwargs):
    # ... åŸæœ‰ä»£ç  ...
    
    # è®¡ç®—ä¸»æŸå¤±
    loss = loss_flow.mean() + loss_ct.mean()
    
    # ğŸ”¥ æ–°å¢ï¼šGateæ­£åˆ™åŒ–æŸå¤±
    gate_reg_loss = 0.0
    if self.use_gate_attn and self.training:
        for block in self.model.blocks:
            if hasattr(block.cross_attn, '_gate_penalty'):
                gate_reg_loss += block.cross_attn._gate_penalty
        
        # æ­£åˆ™åŒ–æƒé‡ï¼ˆå¯è°ƒæ•´ï¼‰
        gate_reg_weight = 0.01  # èŒƒå›´: 0.001-0.1
        loss = loss + gate_reg_weight * gate_reg_loss
        
        loss_dict['gate_reg_loss'] = gate_reg_loss.item()
    
    return loss, loss_dict
```

---

### æ–¹æ¡ˆBï¼šè°ƒæ•´è®­ç»ƒè¶…å‚æ•°ï¼ˆå¯åœ¨å½“å‰checkpointç»§ç»­ï¼‰

å¦‚æœä¸æƒ³é‡å¯è®­ç»ƒï¼Œå¯ä»¥å°è¯•ä»¥ä¸‹è°ƒæ•´ï¼š

#### ä¿®æ”¹é…ç½®æ–‡ä»¶ `flow_tactile_image_policy_gateattn.yaml`

```yaml
optimizer:
  _target_: torch.optim.AdamW
  lr: 1.0e-4  # ğŸ”¥ é™ä½å­¦ä¹ ç‡ (åŸ: 5.0e-4)
  betas: [0.9, 0.95]
  eps: 1.0e-8
  weight_decay: 5.0e-3  # ğŸ”¥ å¢åŠ weight decay (åŸ: 1.0e-3)

training:
  max_grad_norm: 2.0  # ğŸ”¥ é™ä½æ¢¯åº¦è£å‰ª (åŸ: 5.0)
  
  # ğŸ”¥ æ–°å¢ï¼šæ—©åœç­–ç•¥
  early_stopping_patience: 20  # val_lossè¿ç»­20ä¸ªepochä¸é™å°±åœæ­¢
  
dataloader:
  batch_size: 64  # ğŸ”¥ å‡å°batch size (åŸ: 112)
  
  # ğŸ”¥ å¢å¼ºæ•°æ®å¢å¼º
obs_encoder:
  transforms:
    - type: RandomCrop
      ratio: 0.90  # ğŸ”¥ æ›´æ¿€è¿›çš„è£å‰ª (åŸ: 0.95)
    - _target_: torchvision.transforms.RandomRotation
      degrees: [-10.0, 10.0]  # ğŸ”¥ æ›´å¤§çš„æ—‹è½¬ (åŸ: [-5, 5])
    - _target_: torchvision.transforms.ColorJitter
      brightness: 0.4  # ğŸ”¥ å¢å¼º (åŸ: 0.3)
      contrast: 0.5    # ğŸ”¥ å¢å¼º (åŸ: 0.4)
      saturation: 0.6  # ğŸ”¥ å¢å¼º (åŸ: 0.5)
      hue: 0.15        # ğŸ”¥ å¢å¼º (åŸ: 0.08)
    # ğŸ”¥ æ–°å¢ï¼šéšæœºæ“¦é™¤
    - _target_: torchvision.transforms.RandomErasing
      p: 0.3
      scale: [0.02, 0.15]
      ratio: [0.3, 3.3]

policy:
  n_layer: 8  # ğŸ”¥ å‡å°‘å±‚æ•° (åŸ: 12)
  n_emb: 512  # ğŸ”¥ å‡å°‘éšè—ç»´åº¦ (åŸ: 768)
```

---

### æ–¹æ¡ˆCï¼šæ£€æŸ¥æ•°æ®è´¨é‡ï¼ˆå¹¶è¡Œè¿›è¡Œï¼‰

#### 1. æ£€æŸ¥å„æ¨¡æ€çš„æ•°æ®ç»Ÿè®¡

åˆ›å»ºè¯Šæ–­è„šæœ¬ `diagnose_modality_data.py`:

```python
import zarr
import numpy as np
from pathlib import Path

def diagnose_dataset(zarr_path):
    """è¯Šæ–­æ•°æ®é›†å„æ¨¡æ€çš„è´¨é‡"""
    root = zarr.open(zarr_path, 'r')
    
    print("=" * 60)
    print("æ•°æ®é›†è¯Šæ–­æŠ¥å‘Š")
    print("=" * 60)
    
    # æ£€æŸ¥å„æ¨¡æ€çš„ç»Ÿè®¡ä¿¡æ¯
    modalities = {
        'head_cam': 'data/img/head_cam',
        'left_wrist': 'data/img/left_wrist_cam', 
        'right_wrist': 'data/img/right_wrist_cam',
        'left_tactile': 'data/img/left_tactile',
        'right_tactile': 'data/img/right_tactile',
        'proprio': 'data/state'
    }
    
    for name, path in modalities.items():
        try:
            data = root[path]
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            sample = data[:100]  # é‡‡æ ·å‰100å¸§
            mean = np.mean(sample)
            std = np.std(sample)
            min_val = np.min(sample)
            max_val = np.max(sample)
            
            print(f"\n{name}:")
            print(f"  Shape: {data.shape}")
            print(f"  Mean: {mean:.4f}")
            print(f"  Std: {std:.4f}")
            print(f"  Range: [{min_val:.4f}, {max_val:.4f}]")
            
            # æ£€æŸ¥å¼‚å¸¸
            if std < 0.01:
                print(f"  âš ï¸  è­¦å‘Š: æ ‡å‡†å·®è¿‡ä½ï¼Œæ•°æ®å¯èƒ½ç¼ºä¹å¤šæ ·æ€§")
            if mean < 0.01 or mean > 254:
                print(f"  âš ï¸  è­¦å‘Š: å‡å€¼å¼‚å¸¸ï¼Œæ£€æŸ¥å½’ä¸€åŒ–")
            
        except Exception as e:
            print(f"\n{name}: âŒ æ— æ³•è¯»å– ({e})")
    
    print("\n" + "=" * 60)

# ä½¿ç”¨æ–¹æ³•
diagnose_dataset("path/to/your/dataset.zarr")
```

#### 2. å¯è§†åŒ–å„æ¨¡æ€çš„æ³¨æ„åŠ›åˆ†å¸ƒ

åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ å¯è§†åŒ–ï¼š

```python
# åœ¨ train_maniflow_robotwin2_workspace.py ä¸­
if self.global_step % 500 == 0:
    # ... åŸæœ‰attentionè®°å½•ä»£ç  ...
    
    # ğŸ”¥ æ–°å¢ï¼šè¯¦ç»†çš„æ¨¡æ€åˆ†æ
    if attn_stats is not None:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡æ€è¢«ä¸¥é‡å¿½ç•¥
        for modality in ['head', 'wrist', 'tactile', 'proprio']:
            attn_key = f'attn/modality_{modality}'
            if attn_key in attn_stats:
                attn_val = attn_stats[attn_key]
                if attn_val < 0.05:
                    logger.warning(
                        f"âš ï¸  {modality}æ¨¡æ€æ³¨æ„åŠ›è¿‡ä½: {attn_val:.4f}, "
                        f"æ£€æŸ¥æ•°æ®è´¨é‡æˆ–ç‰¹å¾æå–"
                    )
```

---

## ğŸ“Š éœ€è¦é‡ç‚¹ç›‘æ§çš„å‚æ•°

### 1. Gateå¥åº·åº¦æŒ‡æ ‡ï¼ˆæœ€å…³é”®ï¼‰

```python
# WandBä¸­åˆ›å»ºè‡ªå®šä¹‰é¢æ¿
é‡ç‚¹æ›²çº¿ç»„åˆï¼š
1. gate/mean_activation (ç›®æ ‡: 0.4-0.6)
2. gate/saturation_low_ratio (ç›®æ ‡: <0.2)
3. gate/saturation_high_ratio (ç›®æ ‡: <0.3)
```

**åˆ¤æ–­æ ‡å‡†**:
- âœ… å¥åº·: `mean_activation` ä»0.1é€æ¸ä¸Šå‡åˆ°0.4+
- âš ï¸  è­¦å‘Š: `mean_activation` æŒç»­<0.2è¶…è¿‡1000æ­¥
- âŒ å¤±è´¥: `mean_activation` æŒç»­<0.1è¶…è¿‡2000æ­¥ â†’ éœ€è¦é‡å¯

### 2. è¿‡æ‹ŸåˆæŒ‡æ ‡

```python
é‡ç‚¹æ›²çº¿ç»„åˆï¼š
1. train_loss vs val_loss (å·®è·åº”<20%)
2. train_action_mse_error (åº”æŒç»­ä¸‹é™)
3. val_lossçš„ç§»åŠ¨å¹³å‡ (åº”ä¸‹é™æˆ–ç¨³å®š)
```

**åˆ¤æ–­æ ‡å‡†**:
- âœ… å¥åº·: `val_loss` è·Ÿéš `train_loss` ä¸‹é™
- âš ï¸  è­¦å‘Š: `val_loss` åœæ­¢ä¸‹é™ä½†train_lossç»§ç»­é™
- âŒ è¿‡æ‹Ÿåˆ: `val_loss` ä¸Šå‡ä¸” `train_loss` ä¸‹é™

### 3. æ¨¡æ€åˆ©ç”¨ç‡

```python
é‡ç‚¹æ›²çº¿ç»„åˆï¼š
1. gate/modality_*_mean (æ‰€æœ‰æ¨¡æ€)
2. attn/modality_* (æ‰€æœ‰æ¨¡æ€)
```

**åˆ¤æ–­æ ‡å‡†**:
- âœ… å¥åº·: æ‰€æœ‰æ¨¡æ€gateå€¼åœ¨0.2-0.8
- âš ï¸  è­¦å‘Š: æŸæ¨¡æ€gateå€¼<0.15
- âŒ å¤±è´¥: æŸæ¨¡æ€gateå€¼<0.05 â†’ è¯¥æ¨¡æ€è¢«å¿½ç•¥

### 4. æ¢¯åº¦æµå¥åº·åº¦

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ æ¢¯åº¦ç›‘æ§
if self.global_step % 100 == 0:
    grad_norms = {}
    for name, param in self.model.named_parameters():
        if param.grad is not None:
            grad_norms[f'grad/{name}'] = param.grad.norm().item()
    
    # ç‰¹åˆ«å…³æ³¨gateç›¸å…³çš„æ¢¯åº¦
    gate_grad_norms = {k: v for k, v in grad_norms.items() if 'gate' in k}
    if gate_grad_norms:
        avg_gate_grad = np.mean(list(gate_grad_norms.values()))
        step_log['grad/gate_avg'] = avg_gate_grad
        
        if avg_gate_grad < 1e-6:
            logger.warning("âš ï¸  Gateæ¢¯åº¦è¿‡å°ï¼Œå¯èƒ½å‡ºç°æ¢¯åº¦æ¶ˆå¤±")
```

**åˆ¤æ–­æ ‡å‡†**:
- âœ… å¥åº·: gateæ¢¯åº¦åœ¨1e-4åˆ°1e-1ä¹‹é—´
- âš ï¸  è­¦å‘Š: gateæ¢¯åº¦<1e-5
- âŒ æ¢¯åº¦æ¶ˆå¤±: gateæ¢¯åº¦<1e-7

### 5. å­¦ä¹ ç‡ä¸æŸå¤±çš„å…³ç³»

```python
é‡ç‚¹æ›²çº¿ç»„åˆï¼š
1. lr (å­¦ä¹ ç‡æ›²çº¿)
2. train_loss (è®­ç»ƒæŸå¤±)
3. loss_flow vs loss_ct (ä¸¤è€…æ¯”ä¾‹)
```

**åˆ¤æ–­æ ‡å‡†**:
- âœ… å¥åº·: æŸå¤±éšlr warmupå¹³æ»‘ä¸‹é™
- âš ï¸  è­¦å‘Š: æŸå¤±éœ‡è¡å‰§çƒˆ
- âŒ ä¸ç¨³å®š: æŸå¤±å‡ºç°NaNæˆ–çªç„¶æš´æ¶¨

---

## ğŸ¯ åˆ†é˜¶æ®µè¯Šæ–­æµç¨‹

### é˜¶æ®µ1: å‰500æ­¥ï¼ˆåˆå§‹åŒ–æ£€æŸ¥ï¼‰

**æ£€æŸ¥é¡¹**:
- [ ] `gate/mean_activation` æ˜¯å¦åœ¨0.3ä»¥ä¸Šï¼Ÿ
- [ ] `train_loss` æ˜¯å¦å¼€å§‹ä¸‹é™ï¼Ÿ
- [ ] å„æ¨¡æ€gateå€¼æ˜¯å¦éƒ½>0.1ï¼Ÿ

**å¦‚æœä¸æ»¡è¶³** â†’ ç«‹å³åœæ­¢ï¼Œé‡‡ç”¨æ–¹æ¡ˆAé‡å¯

### é˜¶æ®µ2: 500-2000æ­¥ï¼ˆå­¦ä¹ ç¨³å®šæ€§ï¼‰

**æ£€æŸ¥é¡¹**:
- [ ] `gate/mean_activation` æ˜¯å¦ä¸Šå‡åˆ°0.4+ï¼Ÿ
- [ ] `val_loss` æ˜¯å¦è·Ÿéštrain_lossä¸‹é™ï¼Ÿ
- [ ] `saturation_low_ratio` æ˜¯å¦é™åˆ°0.4ä»¥ä¸‹ï¼Ÿ

**å¦‚æœä¸æ»¡è¶³** â†’ é‡‡ç”¨æ–¹æ¡ˆBè°ƒæ•´è¶…å‚æ•°

### é˜¶æ®µ3: 2000-5000æ­¥ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰

**æ£€æŸ¥é¡¹**:
- [ ] `val_loss` æ˜¯å¦æŒç»­ä¸‹é™æˆ–ç¨³å®šï¼Ÿ
- [ ] `train_action_mse_error` æ˜¯å¦<0.05ï¼Ÿ
- [ ] å„æ¨¡æ€gateå€¼æ˜¯å¦éƒ½åœ¨0.2-0.8ï¼Ÿ

**å¦‚æœä¸æ»¡è¶³** â†’ æ£€æŸ¥æ•°æ®è´¨é‡ï¼ˆæ–¹æ¡ˆCï¼‰

### é˜¶æ®µ4: 5000æ­¥åï¼ˆé•¿æœŸç›‘æ§ï¼‰

**æ£€æŸ¥é¡¹**:
- [ ] `val_loss` ä¸ `train_loss` å·®è·æ˜¯å¦<20%ï¼Ÿ
- [ ] Gateç»Ÿè®¡æ˜¯å¦ç¨³å®šï¼ˆä¸å†å‰§çƒˆå˜åŒ–ï¼‰ï¼Ÿ
- [ ] æ¨¡æ€æƒé‡åˆ†å¸ƒæ˜¯å¦ç¬¦åˆä»»åŠ¡ç‰¹æ€§ï¼Ÿ

---

## ğŸ” å¿«é€Ÿè¯Šæ–­å‘½ä»¤

### 1. æ£€æŸ¥å½“å‰è®­ç»ƒçŠ¶æ€

```bash
# æŸ¥çœ‹æœ€è¿‘çš„WandBæ—¥å¿—
python -c "
import wandb
api = wandb.Api()
run = api.run('your-project/run-id')
history = run.history(samples=100)

# å…³é”®æŒ‡æ ‡
print('æœ€è¿‘100æ­¥ç»Ÿè®¡:')
print(f\"mean_activation: {history['gate/mean_activation'].mean():.4f}\")
print(f\"saturation_low: {history['gate/saturation_low_ratio'].mean():.4f}\")
print(f\"val_lossè¶‹åŠ¿: {history['val_loss'].diff().mean():.6f}\")
"
```

### 2. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š

```python
# åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python scripts/diagnose_training.py \
    --checkpoint_path outputs/xxx/checkpoints/latest.ckpt \
    --output_path diagnosis_report.txt
```

---

## ğŸ“ æ¨èçš„é…ç½®ä¿®æ”¹ï¼ˆç«‹å³å¯ç”¨ï¼‰

åˆ›å»ºæ–°é…ç½®æ–‡ä»¶ `flow_tactile_image_policy_gateattn_fixed.yaml`:

```yaml
# ç»§æ‰¿åŸé…ç½®
defaults:
  - flow_tactile_image_policy_gateattn

# ğŸ”¥ å…³é”®ä¿®æ”¹
optimizer:
  lr: 1.0e-4  # é™ä½å­¦ä¹ ç‡
  weight_decay: 5.0e-3  # å¢åŠ æ­£åˆ™åŒ–

training:
  max_grad_norm: 2.0  # æ›´ä¿å®ˆçš„æ¢¯åº¦è£å‰ª
  
dataloader:
  batch_size: 64  # å‡å°batch size

policy:
  n_layer: 8  # å‡å°‘å±‚æ•°
  n_emb: 512  # å‡å°‘æ¨¡å‹å®¹é‡
  
  # ğŸ”¥ å¦‚æœå®ç°äº†gateæ­£åˆ™åŒ–
  gate_reg_weight: 0.01  # Gateæ­£åˆ™åŒ–æƒé‡
  gate_init_bias: 1.0    # Gateåˆå§‹biaså€¼

# ğŸ”¥ æ–°å¢ï¼šæ—©åœ
early_stopping:
  monitor: val_loss
  patience: 20
  mode: min
```

ä½¿ç”¨æ–¹æ³•:
```bash
python train.py --config-name flow_tactile_image_policy_gateattn_fixed
```

---

## âš¡ ç´§æ€¥ä¿®å¤è„šæœ¬

å¦‚æœéœ€è¦åœ¨ä¸é‡å¯çš„æƒ…å†µä¸‹è°ƒæ•´gateå€¼ï¼Œå¯ä»¥ä½¿ç”¨checkpoint surgery:

```python
# checkpoint_gate_fix.py
import torch
import pathlib

def fix_gate_bias(ckpt_path, output_path, new_bias=1.0):
    """
    ä¿®æ”¹checkpointä¸­çš„gate biaså€¼
    
    Args:
        ckpt_path: åŸcheckpointè·¯å¾„
        output_path: ä¿®å¤åçš„checkpointè·¯å¾„
        new_bias: æ–°çš„biaså€¼ï¼ˆå»ºè®®1.0-2.0ï¼‰
    """
    # åŠ è½½checkpoint
    ckpt = torch.load(ckpt_path, map_location='cpu')
    
    # ä¿®æ”¹gate bias
    state_dict = ckpt['state_dicts']['model']
    modified_keys = []
    
    for key in state_dict.keys():
        if 'cross_attn.gate_proj.bias' in key:
            old_bias = state_dict[key].clone()
            # å°†æ‰€æœ‰gate biasè®¾ç½®ä¸ºnew_bias
            state_dict[key] = torch.full_like(old_bias, new_bias)
            modified_keys.append(key)
            print(f"ä¿®æ”¹ {key}: {old_bias.mean():.4f} â†’ {new_bias:.4f}")
    
    # ä¿å­˜ä¿®å¤åçš„checkpoint
    torch.save(ckpt, output_path)
    print(f"\nâœ… å·²ä¿å­˜ä¿®å¤åçš„checkpointåˆ°: {output_path}")
    print(f"   ä¿®æ”¹äº† {len(modified_keys)} ä¸ªgate biaså‚æ•°")
    print(f"\nä½¿ç”¨æ–¹æ³•: å°†æ­¤checkpointå¤åˆ¶ä¸ºlatest.ckptå¹¶ç»§ç»­è®­ç»ƒ")

# ä½¿ç”¨ç¤ºä¾‹
fix_gate_bias(
    ckpt_path='outputs/xxx/checkpoints/latest.ckpt',
    output_path='outputs/xxx/checkpoints/latest_fixed.ckpt',
    new_bias=1.5  # å¯è°ƒæ•´
)
```

---

## ğŸ“ˆ é¢„æœŸæ”¹å–„æ•ˆæœ

### æ–¹æ¡ˆAï¼ˆé‡å¯+ä¿®æ”¹åˆå§‹åŒ–ï¼‰
- **1-500æ­¥**: `mean_activation` åº”ç¨³å®šåœ¨0.5-0.7
- **500-2000æ­¥**: `saturation_low_ratio` é™åˆ°0.2ä»¥ä¸‹
- **2000æ­¥å**: `val_loss` å¼€å§‹ç¨³å®šä¸‹é™

### æ–¹æ¡ˆBï¼ˆè°ƒæ•´è¶…å‚æ•°ï¼‰
- **ç«‹å³**: è¿‡æ‹Ÿåˆé€Ÿåº¦å‡ç¼“
- **1000æ­¥å†…**: `val_loss` åœæ­¢ä¸Šå‡
- **2000æ­¥å**: `gate/mean_activation` ç¼“æ…¢ä¸Šå‡åˆ°0.2+

### æ–¹æ¡ˆCï¼ˆæ•°æ®å¢å¼ºï¼‰
- **é•¿æœŸ**: æ³›åŒ–èƒ½åŠ›æå‡
- **5000æ­¥å**: train/val losså·®è·ç¼©å°

---

## ğŸ†˜ å¦‚æœä»¥ä¸Šæ–¹æ¡ˆéƒ½æ— æ•ˆ

### æœ€åçš„æ’æŸ¥æ–¹å‘

1. **æ£€æŸ¥æ•°æ®é›†æœ¬èº«**
   - è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ†å¸ƒæ˜¯å¦ä¸€è‡´ï¼Ÿ
   - æ˜¯å¦å­˜åœ¨æ ‡æ³¨é”™è¯¯ï¼Ÿ
   - æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿï¼ˆå»ºè®®>10kæ ·æœ¬ï¼‰ï¼Ÿ

2. **æ£€æŸ¥ç‰¹å¾æå–å™¨**
   - RGB encoderæ˜¯å¦æ­£å¸¸å·¥ä½œï¼Ÿ
   - Tactile encoderè¾“å‡ºæ˜¯å¦åˆç†ï¼Ÿ
   - Proprioç‰¹å¾æ˜¯å¦å½’ä¸€åŒ–ï¼Ÿ

3. **å°è¯•ä¸ä½¿ç”¨Gate-Attention**
   ```yaml
   policy:
     use_gate_attn: false  # å›é€€åˆ°æ ‡å‡†DiTX
   ```
   å¦‚æœä¸ä½¿ç”¨gateè®­ç»ƒæ­£å¸¸ï¼Œè¯´æ˜gateæœºåˆ¶å®ç°æœ‰é—®é¢˜

4. **å¯¹æ¯”å®éªŒ**
   - ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆn_layer=4, n_emb=256ï¼‰
   - ä½¿ç”¨æ›´ç®€å•çš„ä»»åŠ¡ï¼ˆå•æ¨¡æ€ï¼‰
   - æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šä»»åŠ¡çš„é—®é¢˜

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2026-02-02  
**é€‚ç”¨äº**: DiTX GateAttnè®­ç»ƒé—®é¢˜è¯Šæ–­
