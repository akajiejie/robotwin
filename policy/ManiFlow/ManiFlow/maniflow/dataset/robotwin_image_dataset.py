from threadpoolctl import threadpool_limits
from typing import Dict, Optional, List
import torch
import numpy as np
import copy
import zarr  
import numcodecs  
from maniflow.common.pytorch_util import dict_apply
from maniflow.common.replay_buffer import ReplayBuffer
from maniflow.common.sampler import (
    SequenceSampler, get_val_mask, downsample_mask)
from maniflow.model.common.normalizer import LinearNormalizer, SingleFieldLinearNormalizer, get_image_range_normalizer
from maniflow.dataset.base_dataset import BaseDataset
from termcolor import cprint

class RoboTwinImageDataset(BaseDataset):
    def __init__(self,
            zarr_path, 
            horizon=1,
            n_obs_steps=2,
            pad_before=0,
            pad_after=0,
            seed=42,
            val_ratio=0.0,
            max_train_episodes=None,
            task_name=None,
            shape_meta: Optional[Dict] = None,
            obs_key_mapping: Optional[Dict[str, str]] = None,  # ðŸ”‘ æ–°å¢žï¼šçµæ´»çš„é”®åæ˜ å°„
            state_key: str = 'state',  # ðŸ”‘ æ–°å¢žï¼šå¯é…ç½®çš„stateé”®å
            action_key: str = 'action',  # ðŸ”‘ æ–°å¢žï¼šå¯é…ç½®çš„actioné”®å
            **kwargs
            ):
        super().__init__()
        self.task_name = task_name
        self.state_key = state_key
        self.action_key = action_key
        
        cprint(f'Loading RoboTwinDataset from {zarr_path}', 'green')

        # ðŸ”‘ åŠ¨æ€è§£æžè§‚å¯Ÿç©ºé—´é…ç½®
        self.rgb_keys = []  # é…ç½®ä¸­çš„RGBé”®ååˆ—è¡¨
        self.low_dim_keys = []  # é…ç½®ä¸­çš„ä½Žç»´é”®ååˆ—è¡¨
        self.obs_key_mapping = {}  # é…ç½®é”® -> ç¼“å†²åŒºé”®çš„æ˜ å°„
        self.obs_types = {}  # è®°å½•æ¯ä¸ªé”®çš„ç±»åž‹
        
        if shape_meta is not None:
            obs_shape_meta = shape_meta.get('obs', {})
            
            for key, attr in obs_shape_meta.items():
                obs_type = attr.get('type', 'low_dim')
                self.obs_types[key] = obs_type
                
                if obs_type == 'rgb':
                    # ç¡®å®šç¼“å†²åŒºé”®å
                    if obs_key_mapping and key in obs_key_mapping:
                        # ä½¿ç”¨è‡ªå®šä¹‰æ˜ å°„
                        buffer_key = obs_key_mapping[key]
                    else:
                        # ä½¿ç”¨é»˜è®¤æ˜ å°„è§„åˆ™ï¼šå°† _cam æ›¿æ¢ä¸º _camera
                        buffer_key = self._default_key_mapping(key)
                    
                    self.rgb_keys.append(key)
                    self.obs_key_mapping[key] = buffer_key
                    cprint(f"  Registered RGB obs: {key} -> buffer key: {buffer_key}", 'cyan')
                    
                elif obs_type == 'low_dim':
                    # ä½Žç»´è§‚å¯Ÿé€šå¸¸ç›´æŽ¥ä»Žstateè¯»å–ï¼Œä½†ä¹Ÿæ”¯æŒè‡ªå®šä¹‰
                    if obs_key_mapping and key in obs_key_mapping:
                        buffer_key = obs_key_mapping[key]
                    else:
                        buffer_key = self.state_key  # é»˜è®¤ä½¿ç”¨state_key
                    
                    self.low_dim_keys.append(key)
                    self.obs_key_mapping[key] = buffer_key
                    cprint(f"  Registered low-dim obs: {key} -> buffer key: {buffer_key}", 'cyan')
                
                else:
                    cprint(f"  Warning: Unknown obs type '{obs_type}' for key '{key}', skipping", 'yellow')
        
        # åŽå¤‡æ–¹æ¡ˆï¼šå¦‚æžœæ²¡æœ‰æä¾›shape_metaï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if len(self.rgb_keys) == 0 and len(self.low_dim_keys) == 0:
            cprint(f"  Warning: No shape_meta provided, using default configuration", 'yellow')
            self.rgb_keys = ['head_cam']
            self.low_dim_keys = ['agent_pos']
            self.obs_key_mapping = {
                'head_cam': 'head_camera',
                'agent_pos': self.state_key
            }
            self.obs_types = {'head_cam': 'rgb', 'agent_pos': 'low_dim'}
            cprint(f"  Default: head_cam -> head_camera", 'yellow')
            cprint(f"  Default: agent_pos -> {self.state_key}", 'yellow')
        
        # ðŸ”‘ åŠ¨æ€æž„å»ºéœ€è¦åŠ è½½çš„ç¼“å†²åŒºé”®åˆ—è¡¨
        buffer_keys = self._get_required_buffer_keys()
        cprint(f"Loading buffer keys: {buffer_keys}", 'green')
        
        # ðŸ”¥ ç›´æŽ¥ä»Žç£ç›˜æŒ‰éœ€è¯»å–,ä¸åŠ è½½åˆ°å†…å­˜ (æ•°æ®é›†78GB,å†…å­˜åªæœ‰110GB)
        cprint(f"âš ï¸  Using on-demand disk loading mode (NO memory copy) - dataset is 78GB", 'red')
        cprint(f"âš ï¸  Data will be read from disk on-the-fly, may be slower but avoids OOM", 'yellow')
        # ç›´æŽ¥æ‰“å¼€zarræ–‡ä»¶,ä¸å¤åˆ¶åˆ°å†…å­˜
        import zarr as zarr_lib
        zarr_group = zarr_lib.open(zarr_path, mode='r')
        
        # åˆ›å»ºè¿‡æ»¤åŽçš„è§†å›¾(åªåŒ…å«éœ€è¦çš„keys)
        filtered_data = {}
        for key in buffer_keys:
            if key in zarr_group['data']:
                filtered_data[key] = zarr_group['data'][key]
        
        # æž„é€ ReplayBufferéœ€è¦çš„ç»“æž„
        # metaéœ€è¦è½¬æ¢ä¸ºnumpyæ•°ç»„(åªæœ‰å…ƒæ•°æ®,å¾ˆå°)
        meta_dict = {}
        for key, value in zarr_group['meta'].items():
            if hasattr(value, 'shape') and len(value.shape) == 0:
                # æ ‡é‡
                meta_dict[key] = np.array(value)
            else:
                # æ•°ç»„(episode_endsç­‰,å¾ˆå°,å¯ä»¥åŠ è½½åˆ°å†…å­˜)
                meta_dict[key] = value[:]
        
        root = {
            'meta': meta_dict,
            'data': filtered_data
        }
        self.replay_buffer = ReplayBuffer(root=root)

        val_mask = get_val_mask(
            n_episodes=self.replay_buffer.n_episodes, 
            val_ratio=val_ratio,
            seed=seed)
        train_mask = ~val_mask

        if max_train_episodes is None:
            max_train_episodes = self.replay_buffer.n_episodes - np.sum(val_mask)
        cprint(f'Maximum training episodes: {max_train_episodes}', 'yellow')
        cprint(f'Validation ratio: {val_ratio}', 'yellow')

        train_mask = downsample_mask(
            mask=train_mask, 
            max_n=max_train_episodes, 
            seed=seed)
        self.sampler = SequenceSampler(
            replay_buffer=self.replay_buffer, 
            sequence_length=horizon,
            pad_before=pad_before, 
            pad_after=pad_after,
            episode_mask=train_mask)
        self.train_mask = train_mask
        self.horizon = horizon
        self.pad_before = pad_before
        self.pad_after = pad_after
        self.n_obs_steps = n_obs_steps

        self.zarr_path = zarr_path
        self.train_episodes_num = np.sum(train_mask)
        self.val_episodes_num = np.sum(val_mask)

    def _default_key_mapping(self, config_key: str) -> str:
        """
        é»˜è®¤çš„é”®åæ˜ å°„è§„åˆ™
        
        ç¤ºä¾‹:
            'head_cam' -> 'head_camera'
            'left_wrist_cam' -> 'left_wrist_camera'
            'rgb_front' -> 'rgb_front' (ä¸å˜)
        """
        if config_key.endswith('_cam'):
            return config_key.replace('_cam', '_camera')
        return config_key
    
    def _get_required_buffer_keys(self) -> List[str]:
        """
        èŽ·å–éœ€è¦ä»Žç¼“å†²åŒºåŠ è½½çš„æ‰€æœ‰å”¯ä¸€é”®
        """
        buffer_keys = set()
        
        # æ·»åŠ æ‰€æœ‰è§‚å¯Ÿé”®å¯¹åº”çš„ç¼“å†²åŒºé”®
        for config_key in self.rgb_keys + self.low_dim_keys:
            buffer_key = self.obs_key_mapping[config_key]
            buffer_keys.add(buffer_key)
        
        # æ·»åŠ actioné”®
        buffer_keys.add(self.action_key)
        
        return sorted(list(buffer_keys))

    def get_validation_dataset(self):
        val_set = copy.copy(self)
        val_set.sampler = SequenceSampler(
            replay_buffer=self.replay_buffer, 
            sequence_length=self.horizon,
            pad_before=self.pad_before, 
            pad_after=self.pad_after,
            episode_mask=~self.train_mask
            )
        val_set.train_mask = ~self.train_mask
        return val_set

    
    def get_normalizer(self, mode='limits', **kwargs):
        """
        åŠ¨æ€åˆ›å»ºå½’ä¸€åŒ–å™¨
        """
        data = {
            'action': self.replay_buffer[self.action_key]
        }

        normalizer = LinearNormalizer()
        normalizer.fit(data=data, last_n_dims=1, mode=mode, **kwargs)
        
        # ðŸ”‘ ä¸ºæ‰€æœ‰è§‚å¯Ÿé”®æ·»åŠ identity normalizer
        for config_key in self.rgb_keys + self.low_dim_keys:
            normalizer[config_key] = SingleFieldLinearNormalizer.create_identity()
        
        return normalizer


    def __len__(self) -> int:
        return len(self.sampler)

    def _sample_to_data(self, sample):
        """
        å°†åŽŸå§‹æ ·æœ¬è½¬æ¢ä¸ºæ¨¡åž‹éœ€è¦çš„æ•°æ®æ ¼å¼
        """
        obs_dict = {}
        
        # ðŸ”‘ åŠ¨æ€åŠ è½½æ‰€æœ‰RGBè§‚å¯Ÿ
        for config_key in self.rgb_keys:
            buffer_key = self.obs_key_mapping[config_key]
            if buffer_key in sample:
                # RGBæ•°æ®ï¼šå‡è®¾æ˜¯uint8 [0-255]ï¼Œå½’ä¸€åŒ–åˆ°[0-1]
                raw_data = sample[buffer_key][:,].astype(np.float32)
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å½’ä¸€åŒ–
                if raw_data.max() > 1.0:
                    raw_data = raw_data / 255.0
                obs_dict[config_key] = raw_data
            else:
                cprint(f"Warning: RGB key '{buffer_key}' not found in sample, skipping", 'red')
        
        # ðŸ”‘ åŠ¨æ€åŠ è½½æ‰€æœ‰ä½Žç»´è§‚å¯Ÿ
        for config_key in self.low_dim_keys:
            buffer_key = self.obs_key_mapping[config_key]
            if buffer_key in sample:
                # ä½Žç»´æ•°æ®ï¼šç›´æŽ¥ä½¿ç”¨
                obs_dict[config_key] = sample[buffer_key][:,].astype(np.float32)
            else:
                cprint(f"Warning: Low-dim key '{buffer_key}' not found in sample, skipping", 'red')
        
        # ðŸ”‘ åŠ è½½action
        if self.action_key not in sample:
            raise KeyError(f"Action key '{self.action_key}' not found in sample!")
        
        data = {
            'obs': obs_dict,
            'action': sample[self.action_key].astype(np.float32)
        }

        return data
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        threadpool_limits(1)
        sample = self.sampler.sample_sequence(idx)
        data = self._sample_to_data(sample)
        # to save RAM, only return first n_obs_steps of OBS
        # since the rest will be discarded anyway.
        # when self.n_obs_steps is None
        # this slice does nothing (takes all)
        T_slice = slice(self.n_obs_steps)
        data['obs'] = {k: v[T_slice] for k, v in data['obs'].items()}
        torch_data = dict_apply(data, torch.from_numpy)

        return torch_data
