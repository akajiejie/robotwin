# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.
# --------------------------------------------------------
# References:
# policyconsensusï¼šhttps://github.com/policyconsensus/policyconsensus.git
# ManiFlow: https://github.com/geyan21/ManiFlow_Policy
# touch_in_the_wild:https://github.com/YolandaXinyueZhu/touch_in_the_wild.git
# --------------------------------------------------------
from typing import Dict
import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
from maniflow.common.pytorch_util import replace_submodules
from maniflow.model.tactile.base_sensor import BaseSensoryEncoder


class TimmTactileEncoder(BaseSensoryEncoder):
    """ä½¿ç”¨timmåº“çš„è§¦è§‰ç¼–ç å™¨ï¼Œå¤ç”¨ResNet18å¤„ç†è§¦è§‰æ•°æ®"""
    
    def __init__(self,
        shape_meta: dict,
        model_name: str = 'resnet18',
        pretrained: bool = False,
        frozen: bool = False,
        use_group_norm: bool = True,
        share_tactile_model: bool = False,
        feature_dim: int = 768,
        output_all_patches: bool = False,
    ):
        super().__init__()
        
        tactile_keys = []
        key_shape_map = {}
        for key, attr in shape_meta['obs'].items():
            if attr.get('type') == 'rgb' and 'tactile' in key.lower():
                tactile_keys.append(key)
                key_shape_map[key] = tuple(attr['shape'])
        
        tactile_keys = sorted(tactile_keys)
        self.output_all_patches = output_all_patches
        
        key_model_map = nn.ModuleDict()
        
        if share_tactile_model and len(tactile_keys) > 0:
            shared_model = self._create_tactile_model(
                key_shape_map[tactile_keys[0]], 
                model_name, pretrained, frozen, use_group_norm, feature_dim
            )
            for key in tactile_keys:
                key_model_map[key] = shared_model
        else:
            for key in tactile_keys:
                key_model_map[key] = self._create_tactile_model(
                    key_shape_map[key],
                    model_name, pretrained, frozen, use_group_norm, feature_dim
                )
        
        self.tactile_keys = tactile_keys
        self.key_model_map = key_model_map
        self.key_shape_map = key_shape_map
        self.feature_dim = feature_dim
        
        print(f"âœ“ è§¦è§‰ç¼–ç å™¨è¾“å‡ºæ¨¡å¼: {'all_patches' if output_all_patches else 'aggregated'}")
        
    def _create_tactile_model(self, shape, model_name, pretrained, frozen, use_group_norm, feature_dim):
        in_channels = shape[0]
        
        model = timm.create_model(
            model_name=model_name,
            pretrained=pretrained,
            in_chans=in_channels,
            global_pool='',
            num_classes=0
        )
        
        if frozen:
            for param in model.parameters():
                param.requires_grad = False
        
        if model_name.startswith('resnet'):
            modules = list(model.children())[:-2]
            backbone = nn.Sequential(*modules)
        else:
            raise NotImplementedError(f"Unsupported model: {model_name}")
        
        #use group norm to replace batch norm
        if use_group_norm:
            backbone = replace_submodules(
                root_module=backbone,
                predicate=lambda x: isinstance(x, nn.BatchNorm2d),
                func=lambda x: nn.GroupNorm(
                    num_groups=max(1, x.num_features // 16), 
                    num_channels=x.num_features
                )
            )
        
        if self.output_all_patches:
            conv_proj = nn.Conv2d(512, feature_dim, kernel_size=1)
            return nn.Sequential(backbone, conv_proj)
        else:
            # ğŸ”¥ ä½¿ç”¨æ”¹è¿›çš„SpatialSoftmaxï¼ˆå‚è€ƒrobomimicï¼‰
            # SpatialSoftmaxè¾“å‡º: (B, 512) -> (B, 512*2) = (B, 1024)
            spatial_softmax = SpatialSoftmax(temperature=1.0)
            projection = nn.Linear(512 * 2, feature_dim)
            return nn.Sequential(backbone, spatial_softmax, projection)
    
    def modalities(self):
        return ['tactile']
    
    def forward(self, obs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        output = {}
        
        for key in self.tactile_keys:
            if key not in obs:
                continue
            
            tactile_data = obs[key]
            
            if len(tactile_data.shape) == 5:
                B, T = tactile_data.shape[:2]
                tactile_data = tactile_data.reshape(B * T, *tactile_data.shape[2:])
            else:
                B = tactile_data.shape[0]
                T = 1
            
            # ğŸ”¥ ä¿®å¤ï¼šå½’ä¸€åŒ–æ—¶ä¿æŒæ¢¯åº¦è¿æ¥
            # ä½¿ç”¨æ¡ä»¶å½’ä¸€åŒ–ï¼Œç¡®ä¿æ¢¯åº¦èƒ½å¤Ÿåå‘ä¼ æ’­
            # æ³¨æ„ï¼šä¸èƒ½ç”¨ with torch.no_grad() åŒ…è£¹å½’ä¸€åŒ–æ“ä½œæœ¬èº«
            with torch.no_grad():
                max_val = tactile_data.max().item()
            
            if max_val > 1.0:
                # å…³é”®ï¼šè¿™ä¸ªé™¤æ³•æ“ä½œå¿…é¡»åœ¨æ¢¯åº¦è®¡ç®—å›¾ä¸­
                tactile_data = tactile_data / 255.0
            
            expected_shape = self.key_shape_map[key]
            if tactile_data.shape[-2] < 64:
                 tactile_data = F.interpolate(
                    tactile_data, 
                    size=(64, 128),  # å¼ºåˆ¶æ”¾å¤§
                    mode='bilinear', 
                    align_corners=False
                )
            
            feature = self.key_model_map[key](tactile_data)
            
            if self.output_all_patches:
                BT, D, H, W = feature.shape
                feature = feature.flatten(2).transpose(1, 2)
                feature = feature.reshape(B, T * H * W, D)
            else:
                feature = feature.reshape(B, T, -1)
            
            output[key] = feature
        
        return output
    
    def output_feature_dim(self):
        return {key: self.feature_dim for key in self.tactile_keys}


class SpatialSoftmax(nn.Module):
    """
    Spatial Softmaxæ± åŒ–å±‚ï¼ˆå‚è€ƒrobomimicå®ç°ï¼‰
    
    è¾“å‡ºæ¯ä¸ªé€šé“çš„æœŸæœ›åæ ‡(x,y)ï¼Œå¯ä»¥ä¿ç•™ç©ºé—´ä¿¡æ¯åŒæ—¶é™ç»´
    å…³é”®æ”¹è¿›ï¼šç¡®ä¿æ¢¯åº¦èƒ½å¤Ÿæ­£ç¡®åå‘ä¼ æ’­åˆ°è¾“å…¥ç‰¹å¾å›¾
    """
    
    def __init__(self, temperature=1.0, normalize=False):
        super().__init__()
        self.temperature = temperature
        self.normalize = normalize
    
    def forward(self, x):
        """
        Args:
            x: (B, C, H, W) ç‰¹å¾å›¾
        Returns:
            output: (B, C*2) æ¯ä¸ªé€šé“çš„(x,y)åæ ‡
        """
        B, C, H, W = x.shape
        
        # åˆ›å»ºå½’ä¸€åŒ–çš„åæ ‡ç½‘æ ¼ [-1, 1]
        # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿åæ ‡ç½‘æ ¼æ­£ç¡®åˆ›å»ºä¸”ä¸æ–­å¼€æ¢¯åº¦
        pos_x = torch.linspace(-1, 1, W, device=x.device, dtype=x.dtype)
        pos_y = torch.linspace(-1, 1, H, device=x.device, dtype=x.dtype)
        # ä½¿ç”¨ meshgrid åˆ›å»ºåæ ‡ç½‘æ ¼ï¼Œæ³¨æ„è¾“å‡ºé¡ºåº
        pos_y, pos_x = torch.meshgrid(pos_y, pos_x, indexing='ij')  # (H, W)
        
        # Reshape for broadcasting: (1, 1, H, W)
        pos_x = pos_x.reshape(1, 1, H, W)
        pos_y = pos_y.reshape(1, 1, H, W)
        
        # Flatten spatial dimensions: (B, C, H*W)
        x_flat = x.reshape(B, C, -1)
        
        # æ•°å€¼ç¨³å®šæ€§ï¼šå‡å»æœ€å¤§å€¼ï¼ˆå¯é€‰ï¼‰
        if self.normalize:
            x_flat = x_flat - x_flat.max(dim=-1, keepdim=True)[0]
        
        # è®¡ç®—softmaxæƒé‡: (B, C, H*W)
        # ğŸ”¥ å…³é”®ï¼šç¡®ä¿temperatureå‚ä¸è®¡ç®—å›¾
        weights = F.softmax(x_flat / self.temperature, dim=-1)
        
        # Reshape weights for spatial operations: (B, C, H, W)
        weights = weights.reshape(B, C, H, W)
        
        # è®¡ç®—æœŸæœ›åæ ‡ï¼ˆåŠ æƒå¹³å‡ï¼‰
        # ğŸ”¥ è¿™é‡Œçš„ä¹˜æ³•å’Œæ±‚å’Œæ“ä½œéƒ½æ˜¯å¯å¾®çš„
        expected_x = (weights * pos_x).sum(dim=[2, 3])  # (B, C)
        expected_y = (weights * pos_y).sum(dim=[2, 3])  # (B, C)
        
        # æ‹¼æ¥xå’Œyåæ ‡: (B, C*2)
        output = torch.cat([expected_x, expected_y], dim=-1)
        
        return output


if __name__ == '__main__':
    print("\n=== TimmTactileEncoder æµ‹è¯• ===\n")
    
    # æ„é€ shape_meta
    shape_meta = {
        'obs': {
            'head_cam': {'shape': [3, 224, 224], 'type': 'rgb', 'horizon': 2},
            'left_wrist_cam': {'shape': [3, 224, 224], 'type': 'rgb', 'horizon': 2},
            'right_wrist_cam': {'shape': [3, 224, 224], 'type': 'rgb', 'horizon': 2},
            'left_tactile': {'shape': [1, 16, 32], 'type': 'rgb', 'horizon': 2},
            'right_tactile': {'shape': [1, 16, 32], 'type': 'rgb', 'horizon': 2},
            'agent_pos': {'shape': [14], 'type': 'low_dim', 'horizon': 2},
        }
    }
    
    # åˆ›å»ºå…±äº«æƒé‡ç¼–ç å™¨
    encoder = TimmTactileEncoder(
        shape_meta=shape_meta,
        model_name='resnet18',
        pretrained=False,
        frozen=False,
        use_group_norm=True,
        share_tactile_model=True,
        feature_dim=768
    )
    
    print(f"è§¦è§‰ä¼ æ„Ÿå™¨: {encoder.tactile_keys}")
    print(f"ç‰¹å¾ç»´åº¦: {list(encoder.output_feature_dim().values())[0]}D")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in encoder.parameters()):,}")
    print(f"æƒé‡å…±äº«: {encoder.key_model_map['left_tactile'] is encoder.key_model_map['right_tactile']}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    obs = {
        'left_tactile': torch.randn(4, 2, 1, 16, 32),
        'right_tactile': torch.randn(4, 2, 1, 16, 32),
    }
    
    with torch.no_grad():
        out = encoder(obs)
    
    print(f"\nè¾“å…¥: [B=4, T=2, C=1, H=16, W=32]")
    print(f"è¾“å‡º: {list(out.values())[0].shape} -> æœŸæœ›: [B=4, T=2, D=768]")
    assert list(out.values())[0].shape == (4, 2, 768), "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼"
    
    print("\n=== æ¢¯åº¦æµ‹è¯• ===")
    encoder.train()
    encoder.zero_grad()
    
    obs_grad = {
        'left_tactile': torch.randn(2, 2, 1, 16, 32, requires_grad=True),
        'right_tactile': torch.randn(2, 2, 1, 16, 32, requires_grad=True),
    }
    
    intermediate_outputs = {}
    hooks = []
    
    def save_grad_hook(name):
        def hook(module, grad_input, grad_output):
            if grad_output[0] is not None:
                intermediate_outputs[f'{name}_grad_out'] = grad_output[0].norm().item()
            if grad_input[0] is not None:
                intermediate_outputs[f'{name}_grad_in'] = grad_input[0].norm().item()
        return hook
    
    model = encoder.key_model_map['left_tactile']
    for i, module in enumerate(model):
        hook = module.register_full_backward_hook(save_grad_hook(f'module_{i}_{module.__class__.__name__}'))
        hooks.append(hook)
    
    output = encoder(obs_grad)
    loss = sum(v.sum() for v in output.values())
    loss.backward()
    
    for hook in hooks:
        hook.remove()
    
    left_grad_norm = obs_grad['left_tactile'].grad.norm().item()
    right_grad_norm = obs_grad['right_tactile'].grad.norm().item()
    
    print(f"\nè¾“å…¥æ¢¯åº¦:")
    print(f"  left_tactile: {left_grad_norm:.6f}")
    print(f"  right_tactile: {right_grad_norm:.6f}")
    
    assert left_grad_norm > 0, "left_tactileæ¢¯åº¦ä¸º0"
    assert right_grad_norm > 0, "right_tactileæ¢¯åº¦ä¸º0"
    assert not torch.isnan(obs_grad['left_tactile'].grad).any(), "æ¢¯åº¦åŒ…å«NaN"
    
    print(f"\nä¸­é—´å±‚æ¢¯åº¦æµ:")
    for name in sorted(intermediate_outputs.keys()):
        print(f"  {name}: {intermediate_outputs[name]:.6f}")
    
    param_grads = []
    for name, param in encoder.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm().item()
            param_grads.append((name, grad_norm))
    
    print(f"\næ¨¡å‹å‚æ•°æ¢¯åº¦:")
    print(f"  æœ‰æ¢¯åº¦å‚æ•°: {len(param_grads)}/{sum(1 for p in encoder.parameters())}")
    if param_grads:
        avg_grad = sum(g for _, g in param_grads) / len(param_grads)
        max_grad = max(param_grads, key=lambda x: x[1])
        min_grad = min(param_grads, key=lambda x: x[1])
        print(f"  å¹³å‡æ¢¯åº¦: {avg_grad:.6f}")
        print(f"  æœ€å¤§æ¢¯åº¦: {max_grad[0]} = {max_grad[1]:.6f}")
        print(f"  æœ€å°æ¢¯åº¦: {min_grad[0]} = {min_grad[1]:.6f}")
    
    spatial_softmax_found = False
    for name, module in encoder.key_model_map['left_tactile'].named_modules():
        if isinstance(module, SpatialSoftmax):
            spatial_softmax_found = True
            break
    
    print(f"\nSpatialSoftmaxæ£€æŸ¥:")
    print(f"  æ¨¡å—å­˜åœ¨: {spatial_softmax_found}")
    if 'module_1_SpatialSoftmax_grad_in' in intermediate_outputs:
        print(f"  è¾“å…¥æ¢¯åº¦: {intermediate_outputs['module_1_SpatialSoftmax_grad_in']:.6f}")
    if 'module_1_SpatialSoftmax_grad_out' in intermediate_outputs:
        print(f"  è¾“å‡ºæ¢¯åº¦: {intermediate_outputs['module_1_SpatialSoftmax_grad_out']:.6f}")
    
    print("\nâœ… æ¢¯åº¦æµ‹è¯•é€šè¿‡\n")
