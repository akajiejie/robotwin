# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.
# --------------------------------------------------------
# References:
# policyconsensusï¼šhttps://github.com/policyconsensus/policyconsensus.git
# ManiFlow: https://github.com/geyan21/ManiFlow_Policy
# touch_in_the_wild:https://github.com/YolandaXinyueZhu/touch_in_the_wild.git
# --------------------------------------------------------
from typing import Dict
import torch
import torch.nn as nn
import torch.nn.functional as F
import timm
from maniflow.common.pytorch_util import replace_submodules
from maniflow.model.tactile.base_sensor import BaseSensoryEncoder

class TimmTactileEncoder(BaseSensoryEncoder):
    """ä½¿ç”¨timmåº“çš„è§¦è§‰ç¼–ç å™¨ï¼Œå¤ç”¨ResNet18å¤„ç†è§¦è§‰æ•°æ®"""
    
    def __init__(self,
        shape_meta: dict,
        model_name: str = 'resnet18',
        pretrained: bool = False,
        frozen: bool = False,
        use_group_norm: bool = True,
        share_tactile_model: bool = False,
        feature_dim: int = 768,  # è¾“å‡ºç‰¹å¾ç»´åº¦ï¼Œå¯¹åº”CLIP cls token
        output_all_patches: bool = False,  # ğŸ”¥ æ˜¯å¦è¾“å‡ºæ‰€æœ‰patch tokensï¼ˆç±»ä¼¼ViTï¼‰
    ):
        super().__init__()
        
        # ç­›é€‰è§¦è§‰æ•°æ®ï¼ˆtype='rgb'ä¸”keyåŒ…å«'tactile'ï¼‰
        tactile_keys = []
        key_shape_map = {}
        for key, attr in shape_meta['obs'].items():
            if attr.get('type') == 'rgb' and 'tactile' in key.lower():
                tactile_keys.append(key)
                key_shape_map[key] = tuple(attr['shape'])
        
        tactile_keys = sorted(tactile_keys)
        
        # ğŸ”¥ æå‰ä¿å­˜output_all_patchesï¼Œå› ä¸º_create_tactile_modeléœ€è¦ä½¿ç”¨å®ƒ
        self.output_all_patches = output_all_patches
        
        # ä¸ºæ¯ä¸ªè§¦è§‰ä¼ æ„Ÿå™¨åˆ›å»ºæˆ–å…±äº«æ¨¡å‹
        key_model_map = nn.ModuleDict()
        
        if share_tactile_model and len(tactile_keys) > 0:
            # å…±äº«æ¨¡å‹ï¼šæ‰€æœ‰è§¦è§‰ä¼ æ„Ÿå™¨ä½¿ç”¨åŒä¸€ä¸ªç½‘ç»œ
            shared_model = self._create_tactile_model(
                key_shape_map[tactile_keys[0]], 
                model_name, pretrained, frozen, use_group_norm, feature_dim
            )
            for key in tactile_keys:
                key_model_map[key] = shared_model
        else:
            # ç‹¬ç«‹æ¨¡å‹ï¼šæ¯ä¸ªè§¦è§‰ä¼ æ„Ÿå™¨æœ‰è‡ªå·±çš„ç½‘ç»œ
            for key in tactile_keys:
                key_model_map[key] = self._create_tactile_model(
                    key_shape_map[key],
                    model_name, pretrained, frozen, use_group_norm, feature_dim
                )
        
        self.tactile_keys = tactile_keys
        self.key_model_map = key_model_map
        self.key_shape_map = key_shape_map
        self.feature_dim = feature_dim
        # self.output_all_patches å·²åœ¨å‰é¢èµ‹å€¼
        
        print(f"âœ“ è§¦è§‰ç¼–ç å™¨è¾“å‡ºæ¨¡å¼: {'all_patches' if output_all_patches else 'aggregated'}", 
               'cyan' if output_all_patches else 'green')
        
    def _create_tactile_model(self, shape, model_name, pretrained, frozen, use_group_norm, feature_dim):
        """åˆ›å»ºå•ä¸ªè§¦è§‰å¤„ç†æ¨¡å‹"""
        in_channels = shape[0]  # è§¦è§‰æ•°æ®çš„é€šé“æ•°
        
        # åˆ›å»ºResNet18æ¨¡å‹
        model = timm.create_model(
            model_name=model_name,
            pretrained=pretrained,
            in_chans=in_channels,  # è‡ªé€‚åº”è¾“å…¥é€šé“æ•°
            global_pool='',  # ä¸ä½¿ç”¨å…¨å±€æ± åŒ–
            num_classes=0
        )
        
        if frozen:
            for param in model.parameters():
                param.requires_grad = False
        
        # æå–ResNet18çš„å·ç§¯å±‚ï¼ˆç§»é™¤æœ€åçš„æ± åŒ–å’ŒFCå±‚ï¼‰
        if model_name.startswith('resnet'):
            # ä¿ç•™åˆ°layer4ï¼Œç§»é™¤avgpoolå’Œfc
            modules = list(model.children())[:-2]
            backbone = nn.Sequential(*modules)
        else:
            raise NotImplementedError(f"Unsupported model: {model_name}")
        
        # æ›¿æ¢BatchNormä¸ºGroupNorm
        if use_group_norm and not pretrained:
            backbone = replace_submodules(
                root_module=backbone,
                predicate=lambda x: isinstance(x, nn.BatchNorm2d),
                func=lambda x: nn.GroupNorm(
                    num_groups=max(1, x.num_features // 16),
                    num_channels=x.num_features
                )
            )
        
        # ğŸ”¥ æ ¹æ®output_all_patcheså†³å®šè¾“å‡ºæ–¹å¼
        if self.output_all_patches:
            # è¾“å‡ºæ‰€æœ‰ç©ºé—´patch tokens: (B, C, H, W) -> (B, H*W, D)
            # ResNet18 layer4è¾“å‡º: 512é€šé“
            # æ·»åŠ 1x1å·ç§¯æŠ•å½±åˆ°ç›®æ ‡ç»´åº¦ï¼Œç„¶åreshapeä¸ºpatch tokens
            conv_proj = nn.Conv2d(512, feature_dim, kernel_size=1)
            return nn.Sequential(backbone, conv_proj)
        else:
            # åŸå§‹æ–¹å¼: SpatialSoftmaxæ± åŒ– + çº¿æ€§æŠ•å½±
            # ResNet18çš„layer4è¾“å‡ºæ˜¯512é€šé“
            spatial_softmax = SpatialSoftmax(temperature=1.0)
            projection = nn.Linear(512 * 2, feature_dim)  # SpatialSoftmaxè¾“å‡º (x,y) åæ ‡ï¼Œæ‰€ä»¥æ˜¯ C*2
            return nn.Sequential(backbone, spatial_softmax, projection)
    
    def modalities(self):
        return ['tactile']
    
    def forward(self, obs: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        è¾“å…¥: obså­—å…¸ï¼Œæ¯ä¸ªè§¦è§‰keyå¯¹åº” (B, T, C, H, W) æˆ– (B, C, H, W)
        è¾“å‡º: 
            - output_all_patches=False: æ¯ä¸ªè§¦è§‰keyå¯¹åº”çš„tokenç‰¹å¾ (B, T, D)ï¼Œä¿ç•™æ—¶åºç»´åº¦
            - output_all_patches=True: æ¯ä¸ªè§¦è§‰keyå¯¹åº”çš„patch tokens (B, T*H*W, D)ï¼Œä¿ç•™æ—¶åºç»´åº¦
        """
        output = {}
        
        for key in self.tactile_keys:
            if key not in obs:
                continue
            
            tactile_data = obs[key]  # (B, T, C, H, W) æˆ– (B, C, H, W)
            
            # å¤„ç†æ—¶åºç»´åº¦
            if len(tactile_data.shape) == 5:
                B, T = tactile_data.shape[:2]
                tactile_data = tactile_data.reshape(B * T, *tactile_data.shape[2:])
            else:
                B = tactile_data.shape[0]
                T = 1
            
            # å½’ä¸€åŒ–åˆ°[0,1]
            if tactile_data.max() > 1.0:
                tactile_data = tactile_data / 255.0
            
            # resizeåˆ°æœŸæœ›çš„shapeï¼ˆå¦‚æœéœ€è¦ï¼‰
            expected_shape = self.key_shape_map[key]
            if tactile_data.shape[1:] != expected_shape:
                target_H, target_W = expected_shape[1], expected_shape[2]
                tactile_data = F.interpolate(
                    tactile_data, 
                    size=(target_H, target_W), 
                    mode='bilinear', 
                    align_corners=False
                )
            
            # å‰å‘ä¼ æ’­
            feature = self.key_model_map[key](tactile_data)
            
            # ğŸ”¥ æ ¹æ®output_all_patcheså†³å®šè¾“å‡ºæ ¼å¼ï¼ˆä¿ç•™æ—¶åºç»´åº¦ï¼‰
            if self.output_all_patches:
                # è¾“å‡ºæ‰€æœ‰patch tokens: (B*T, D, H, W) -> (B, T*H*W, D)
                BT, D, H, W = feature.shape
                feature = feature.flatten(2).transpose(1, 2)  # (B*T, H*W, D)
                feature = feature.reshape(B, T * H * W, D)  # ä¿ç•™æ—¶åºç»´åº¦ -> (B, T*H*W, D)
            else:
                # åŸå§‹æ–¹å¼: èšåˆä¸ºtokenåºåˆ— (B*T, D) -> (B, T, D)
                feature = feature.reshape(B, T, -1)  # ä¿ç•™æ—¶åºç»´åº¦ -> (B, T, D)
            
            output[key] = feature
        
        return output
    
    def output_feature_dim(self):
        """
        è¿”å›æ¯ä¸ªè§¦è§‰ä¼ æ„Ÿå™¨çš„è¾“å‡ºç‰¹å¾ç»´åº¦
        - output_all_patches=False: [B, T, D] (ä¿ç•™æ—¶åºç»´åº¦)
        - output_all_patches=True: [B, T*H*W, D] (ä¿ç•™æ—¶åºç»´åº¦)
        """
        return {key: self.feature_dim for key in self.tactile_keys}


class SpatialSoftmax(nn.Module):
    """Spatial Softmaxæ± åŒ–å±‚ï¼Œè¾“å‡ºç‰¹å¾ç‚¹çš„(x,y)åæ ‡åŠ æƒå’Œ"""
    
    def __init__(self, temperature=1.0, normalize=False):
        super().__init__()
        self.temperature = temperature
        self.normalize = normalize
    
    def forward(self, x):
        """
        è¾“å…¥: (B, C, H, W)
        è¾“å‡º: (B, C*2) - æ¯ä¸ªé€šé“çš„åŠ æƒx,yåæ ‡
        """
        B, C, H, W = x.shape
        
        # åˆ›å»ºåæ ‡ç½‘æ ¼
        pos_x = torch.linspace(-1, 1, W, device=x.device)
        pos_y = torch.linspace(-1, 1, H, device=x.device)
        pos_x, pos_y = torch.meshgrid(pos_x, pos_y, indexing='xy')
        pos_x = pos_x.reshape(1, 1, H * W)
        pos_y = pos_y.reshape(1, 1, H * W)
        
        # Flatten spatialç»´åº¦
        x_flat = x.reshape(B, C, H * W)
        
        # Softmaxè®¡ç®—æƒé‡
        if self.normalize:
            x_flat = x_flat - x_flat.max(dim=-1, keepdim=True)[0]
        weights = F.softmax(x_flat / self.temperature, dim=-1)  # (B, C, H*W)
        
        # åŠ æƒæ±‚å’Œå¾—åˆ°æœŸæœ›åæ ‡
        expected_x = (weights * pos_x).sum(dim=-1)  # (B, C)
        expected_y = (weights * pos_y).sum(dim=-1)  # (B, C)
        
        # æ‹¼æ¥x,yåæ ‡
        output = torch.cat([expected_x, expected_y], dim=-1)  # (B, C*2)
        
        return output


if __name__ == '__main__':
    print("\n=== TimmTactileEncoder æµ‹è¯• ===\n")
    
    # æ„é€ shape_metaï¼ˆè§¦è§‰ç¼–ç å™¨åªéœ€è¦obsï¼Œä¸éœ€è¦actionï¼‰
    shape_meta = {
        'obs': {
            'head_cam': {'shape': [3, 224, 224], 'type': 'rgb', 'horizon': 2},
            'left_wrist_cam': {'shape': [3, 224, 224], 'type': 'rgb', 'horizon': 2},
            'right_wrist_cam': {'shape': [3, 224, 224], 'type': 'rgb', 'horizon': 2},
            'left_tactile': {'shape': [1, 16, 32], 'type': 'rgb', 'horizon': 2},
            'right_tactile': {'shape': [1, 16, 32], 'type': 'rgb', 'horizon': 2},
            'agent_pos': {'shape': [14], 'type': 'low_dim', 'horizon': 2},
        }
    }
    
    # åˆ›å»ºå…±äº«æƒé‡ç¼–ç å™¨ï¼ˆä½¿ç”¨768ç»´è¾“å‡ºï¼Œä¸CLIP cls tokenå¯¹åº”ï¼‰
    encoder = TimmTactileEncoder(
        shape_meta=shape_meta,
        model_name='resnet18',
        pretrained=False,
        frozen=False,
        use_group_norm=True,
        share_tactile_model=True,
        feature_dim=768
    )
    
    print(f"è§¦è§‰ä¼ æ„Ÿå™¨: {encoder.tactile_keys}")
    print(f"ç‰¹å¾ç»´åº¦: {list(encoder.output_feature_dim().values())[0]}D (token format)")
    print(f"å‚æ•°é‡: {sum(p.numel() for p in encoder.parameters()):,}")
    print(f"æƒé‡å…±äº«: {encoder.key_model_map['left_tactile'] is encoder.key_model_map['right_tactile']}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    obs = {
        'left_tactile': torch.randn(4, 2, 1, 16, 32),
        'right_tactile': torch.randn(4, 2, 1, 16, 32),
    }
    
    with torch.no_grad():
        out = encoder(obs)
    
    print(f"\nè¾“å…¥: [B=4, T=2, C=1, H=16, W=32]")
    print(f"è¾“å‡º (ä¿ç•™æ—¶åº): {list(out.values())[0].shape} -> æœŸæœ›: [B=4, T=2, D=768]")
    assert list(out.values())[0].shape == (4, 2, 768), "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼"
    
    # æµ‹è¯•æ¢¯åº¦
    obs_grad = {
        'left_tactile': torch.randn(2, 2, 1, 16, 32, requires_grad=True),
        'right_tactile': torch.randn(2, 2, 1, 16, 32, requires_grad=True),
    }
    output = encoder(obs_grad)
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    for key, feat in output.items():
        assert feat.shape == (2, 2, 768), f"{key} è¾“å‡ºå½¢çŠ¶é”™è¯¯: {feat.shape}"
    
    loss = sum(v.sum() for v in output.values())
    loss.backward()
    
    print(f"æ¢¯åº¦èŒƒæ•°: {obs_grad['left_tactile'].grad.norm().item():.6f}")
    print("\nâœ… æµ‹è¯•é€šè¿‡ - è¾“å‡ºæ ¼å¼: [B, T, 768] ä¿ç•™å®Œæ•´æ—¶åºä¿¡æ¯\n")
