# import packages and module here
import sys

import torch
import sapien.core as sapien
import traceback
import os
import numpy as np
from envs import *
from hydra import initialize, compose
from omegaconf import OmegaConf
from hydra.core.hydra_config import HydraConfig
from hydra import main as hydra_main
import pathlib
from omegaconf import OmegaConf

import yaml
from datetime import datetime
import importlib

from hydra import initialize, compose
from omegaconf import OmegaConf
from datetime import datetime

current_file_path = os.path.abspath(__file__)
parent_directory = os.path.dirname(current_file_path)

sys.path.append(os.path.join(parent_directory, 'ManiFlow'))

from maniflow_policy import *
from maniflow.common.model_util import adjust_intrinsics, resize_depth, depth_to_pointcloud


def encode_obs(observation):  # Post-Process Observation
    obs = dict()
    head_cam = (np.moveaxis(observation["observation"]["head_camera"]["rgb"], -1, 0) / 255)
    left_cam = (np.moveaxis(observation["observation"]["left_camera"]["rgb"], -1, 0) / 255)
    right_cam = (np.moveaxis(observation["observation"]["right_camera"]["rgb"], -1, 0) / 255)
    head_depth = observation["observation"]["head_camera"]["depth"] / 1000.0 # convert mm to meters
    head_intrinsic_cv = observation["observation"]["head_camera"]["intrinsic_cv"]
    head_cam2world_gl = observation["observation"]["head_camera"]["cam2world_gl"]
    # hack here for now, to be fixed later
    head_depth = head_depth.astype(np.float32)
    original_size = (240, 320)  # (height, width) of your current depth/images
    target_size = (224, 224)   # (height, width) target size
    head_depth = resize_depth(head_depth, target_size=target_size)  # Resize to 224x224
    head_intrinsic_cv = adjust_intrinsics(head_intrinsic_cv, original_size, target_size)
    # convert depth map to point cloud
    h, w = head_depth.shape
    head_point_cloud = depth_to_pointcloud(head_depth, head_intrinsic_cv, head_cam2world_gl) # (B, H*W, 3)
    # reshape to (B, H, W, 3)
    head_point_cloud = head_point_cloud.reshape(1, h, w, 3).astype(np.float32)
    # then to (B, 3, H, W)
    head_point_cloud = np.moveaxis(head_point_cloud, -1, 1) # (B, 3, H, W)
    head_point_cloud = head_point_cloud.squeeze(0) # (3, H, W)
            

    obs['agent_pos'] = observation['joint_action']['vector']
    obs['point_cloud'] = observation['pointcloud']
    obs['head_cam'] = head_cam
    obs['left_cam'] = left_cam
    obs['right_cam'] = right_cam
    obs['head_point_cloud'] = head_point_cloud
    obs['head_depth'] = head_depth.astype(np.float32)
    obs['head_intrinsic_cv'] = head_intrinsic_cv.astype(np.float32)
    obs['head_cam2world_gl'] = head_cam2world_gl.astype(np.float32)
    return obs


def get_model(usr_args):
    config_path = "./ManiFlow/maniflow/config"
    config_name = f"{usr_args['config_name']}.yaml"

    with initialize(config_path=config_path, version_base='1.2'):
        cfg = compose(config_name=config_name)

    # now = datetime.now()
    # run_dir = f"data/outputs/{now:%Y.%m.%d}/{now:%H.%M.%S}_{usr_args['config_name']}_{usr_args['task_name']}"

    task_name = usr_args['task_name']
    alg_name = usr_args['alg_name']
    addition_info = usr_args['addition_info']
    seed = usr_args['training_seed']
    exp_name = f"{task_name}-{alg_name}-{addition_info}"
    run_dir = os.path.join(parent_directory, "data", "outputs", exp_name + f"_seed{seed}")


    hydra_runtime_cfg = {
        "job": {
            "override_dirname": usr_args['task_name']
        },
        "run": {
            "dir": run_dir
        },
        "sweep": {
            "dir": run_dir,
            "subdir": "0"
        }
    }
    
    OmegaConf.set_struct(cfg, False)
    cfg.hydra = hydra_runtime_cfg
    cfg.task_name = usr_args["task_name"]
    cfg.expert_data_num = usr_args["expert_data_num"]
    cfg.raw_task_name = usr_args["task_name"]
    OmegaConf.set_struct(cfg, True)

    ManiFlow_Model = ManiFlow(cfg, usr_args, run_dir=run_dir)
    return ManiFlow_Model


def eval(TASK_ENV, model, observation):
    obs = encode_obs(observation)  # Post-Process Observation
    # instruction = TASK_ENV.get_instruction()

    if len(
            model.env_runner.obs
    ) == 0:  # Force an update of the observation at the first frame to avoid an empty observation window, `obs_cache` here can be modified
        model.update_obs(obs)

    actions = model.get_action()  # Get Action according to observation chunk
      # Debugging breakpoint
    for action in actions:  # Execute each step of the action
        TASK_ENV.take_action(action)
        observation = TASK_ENV.get_obs()
        obs = encode_obs(observation)
        model.update_obs(obs)  # Update Observation, `update_obs` here can be modified


# def reset_model(
#         model):  # Clean the model cache at the beginning of every evaluation episode, such as the observation window
#     model.env_runner.reset_obs()

def reset_model(model):
    # Reset temporal aggregation state if enabled
    if model.temporal_agg:
        model.all_time_actions = torch.zeros([
            model.max_timesteps,
            model.max_timesteps + model.num_queries,
            model.state_dim,
        ]).to(model.device)
        model.t = 0
        print("Reset temporal aggregation state")
        # print(f"All time actions: {model.all_time_actions[:3, :3].cpu().numpy()}")  # Print first 10 actions for debugging
    else:
        model.t = 0

    # Reset observation cache
    model.env_runner.reset_obs()
